%!TeX spellcheck = en-US
%!TEX root = ../hw3_report.tex
\subsection*{(a)}

\emph{Comment: We have two alternative solutions in this excersise where we have used the definition of a matrix function in two different ways. Please comment if the second way to solve the problem also is valid, where we see the function $f$ as a function of two variables $f = f(z,t)$ and make a Taylor expansion in $z$ only.}
\subsubsection*{Solution}
Let $\mu \in \mathbb{C}$ be an expansion point, then
\begin{equation}
 f(tA) = \sum\limits_{i = 0}^{\infty} \frac{f^{(i)}(\mu)}{i!}(tA-\mu I)^{i}.
\end{equation}
For $f(z) = \exp(z)$ the function is analytic and we can without loss of generality set $\mu = 0$. For now assume that $\frac{d}{dt}(tA)^{i} = iA(tA)^{i-1}$, then
\begin{equation}
 \frac{d}{dt}\exp(tA) = \frac{d}{dt}\sum\limits_{i = 0}^{\infty} \frac{\exp(0)}{i!}(tA-0 I)^{i} = \sum\limits_{i = 0}^{\infty} \frac{1}{i!}\frac{d}{dt}(tA)^{i} = A\sum\limits_{i = 1}^{\infty}\frac{1}{(i-1)!}\left(tA\right)^{i-1} = A\sum\limits_{i = 0}^{\infty}\frac{1}{i!}\left(tA\right)^{i} = A\exp(tA),
\end{equation}
by shifting the indices $i \rightarrow i + 1$. We now motivate the claim above. By definition
\begin{equation}
  \frac{d}{dt}(tA)^{i} = \lim_{\epsilon\to 0}\frac{((t+\varepsilon)A)^{i} - (tA)^{i}}{\varepsilon} = \lim_{\epsilon\to 0}\frac{(t+\varepsilon)^{i} - t^{i}}{\varepsilon}A^{i} = \frac{d}{dt}(t^{i})A^{i} = iA(tA)^{i-1}.
\end{equation}
Since $it^{i-1}A^{i-1}A = iAt^{i-1}A^{i-1}$ we have $A\exp(tA) = \exp(tA)A=\frac{d}{dt}\exp(tA)$.

%Let $f(z) = \exp (z)$ and $g(z) = dz(t)/dt$, then
%\begin{equation}
%  g(f(tA)) = g\left(\sum\limits_{i = 0}^{\infty} \frac{\exp(\mu)}{i!}(tA-\mu I)^{i}\right) = \sum\limits_{i = 0}^{\infty}\left( \frac{\exp(\mu)}{i!}g((tA-\mu I)^{i})\right) = A\sum\limits_{i = 1}^{\infty}\frac{\exp(\mu)}{(i-1)!}\left(tA-\mu I\right)^{i-1},
%\end{equation}
%be rearranging the indices since $(tA-\mu I)^{0} = I$. The above holds if $g((tA)^{i}) = iA(tA)^{i-1}$. How to show this?

%Anna's attempt:
\subsubsection*{Alternative solution}
Consider the function $f(z,t) = e^{tz}$. We want to investigate the matrix valued function $f(A,t) = e^{Az}$. Let $\mu \in \mathbb{C}$ be an expansion point. Then,
\begin{equation}
  f(A,t) = \sum\limits_{i = 0}^{\infty} \frac{f^{(i)}(\mu,t)}{i!}(A-\mu I)^{i} = \sum\limits_{i = 0}^{\infty} \frac{t^ie^{t\mu}}{i!}(A-\mu I)^{i}.
\end{equation}
If $A\in\mathbb{C}^{n\times n}$, then $f:C^{n \times n}\rightarrow C^{n \times n}$. Now, compute the derivative of $f(A,t)$ with respect to time:
\begin{equation}
\begin{aligned}
\frac{\mathrm d}{\mathrm d t}e^{tA} & = \frac{\mathrm d}{\mathrm dt}\sum^{\infty}_{i = 0} \frac{t^ie^{t\mu}}{i!}(A-\mu I )^i = \\
& = \sum^{\infty}_{i = 0} \frac{\mathrm d}{\mathrm dt}\left(\frac{t^ie^{t\mu}}{i!}(A-\mu I )^i\right) = \\
& = \sum^{\infty}_{i = 0} \frac{\mathrm d}{\mathrm dt}\left(\frac{t^ie^{t\mu}}{i!}\right)(A-\mu I )^i  = \\
&= \sum^{\infty}_{i = 0}  \left(\frac{it^{i-1}e^{t\mu}+t^i\mu e^{t\mu}}{i!}\right) (A-\mu I )^i.
\end{aligned}
\end{equation}
The last expression can be identified as $g(A)$, where $g(z) = ze^{tz}$ as  the expression
\begin{equation}
\left(it^{i-1}e^{t\mu}+t^i\mu e^{t\mu}\right)
\end{equation}
is the $i$th derivative of the product $z\cdot e^{tz}$, which can be seen using the general Leibniz rule ($(f_1f_2)^{(n)} = \sum_{k = 0}^n\binom{n}{k}f_1^{(n-k)}(x)f_2^{(k)}(x)$). Thus, we can conclude that $\frac{\mathrm d }{\mathrm dt}e^{tA} = Ae^{tA}$. The matrix function $e^{tA}A$ has the same Taylor expansion expression as $Ae^{tA}$. Thus, $\frac{\mathrm d }{\mathrm dt}e^{tA} = Ae^{tA} = e^{tA} A$, which is what we wanted to show.

\subsection*{(b)}
Introduce
\begin{equation}
[B,A]_{n} =  [[B,A]_{n-1},A], n = 0,1,2,\ldots, \quad \text{ where }[B,A]_{1} = [B,A] = BA-AB \text{ and } [B,A]_{0} = B.
\end{equation}
We will later in the proof use that $[A+B,C]_{n} = [A,C]_{n} + [B,C]_{n}$, which is shown by induction: the initial case is $[A+B,C]_{1} = AC-CA + BC-CB = [A,C]_{1}+[B,C]_{1}$. Now assume $[A+B,C]_{n} = [A,C]_{n} + [B,C]_{n}$ holds, then
\begin{align}
[A+B,C]_{n+1} &=  [AC-CA + BC-CB,A]_{n} = [AC-CA,C]_{n} + [BC-CB,C]_{n} \\
&= [[A,C],C]_{n} + [[B,C],C]_{n}=[A,C]_{n+1} + [B,C]_{n+1}.
\end{align}


Let $G(t) = \exp(-tA)B\exp(tA)$, which is analytic in $t$. Thus we may write
\begin{equation}
  \label{eq:task7bTaylor}
G(t) = \sum\limits_{i = 0}^{\infty}\frac{t^{i}}{i!} G^{(i)}(\mu)=\sum\limits_{i = 0}^{\infty}\frac{t^{i}}{i!} G_{i},
\end{equation}
where $G_{0} = B$.
By (a) and that $[A+B,C]_{n} = [A,C]_{n} + [B,C]_{n}$ we have that
\begin{equation}
  \frac{d}{dt}G(t) = G(t)A-AG(T) = [G(t),A]=\left[\sum\limits_{i = 0}^{\infty}\frac{t^{i}}{i!} G_{i},A\right] = \sum\limits_{i = 0}^{\infty}\frac{t^{i}}{i!} [G_{i},A]
\end{equation}



 Setting this to be equal to the the derivative of \eqref{eq:task7bTaylor} with respect to $t$ gives
\begin{equation}
\sum\limits_{i = 0}^{\infty}\frac{t^{i}}{i!} [G_{i},A] = \sum\limits_{i = 1}^{\infty}\frac{t^{i-1}}{(i-1)!} G_{i}.
\end{equation}
By shifting the indexing from $i = 1,2,\ldots $ to $i = 0,1,\ldots$ for the right hand side we get
\begin{equation}
\sum\limits_{i = 0}^{\infty}\frac{t^{i}}{i!} [G_{i},A] = \sum\limits_{i = 0}^{\infty}\frac{t^{i}}{i!} G_{i+1}.
\end{equation}
We conclude that $G_{i+1} = [G_{i},A]_{i}$, that is $G_{1} = [G_{0},A]_{0} = B$ and
\begin{equation}
  G(t) = B + t[B,A]+\frac{t^{2}}{2!}[[B,A],A]+\frac{t^{2}}{2!}[[B,A],A,A]+\ldots
\end{equation}

\subsection*{(c)}
We identify the integrand as $G(t)$, that is

\begin{equation}
  P = \int\limits_{0}^{\tau}\,\exp(tA^{T})B\exp(tA)\,dt =\int\limits_{0}^{\tau}\,\exp(-tA)B\exp(tA)\,dt = \int\limits_{0}^{\tau}\,G(t)\,dt.
\end{equation}
Introduce
\begin{equation}
  P_{n} = \int\limits_{0}^{\tau}\,\sum\limits_{i=0}^{n}\frac{t^{i}}{i!}G_{i+1}\, dt=\,\sum\limits_{i=0}^{n}\int\limits_{0}^{\tau}\frac{t^{i}}{i!}G_{i+1}\, dt,
\end{equation}
Since the integrand is uniformly convergent, assuming $\tau$ finite, it holds that
\begin{equation}
  \lim\limits_{n\rightarrow \infty}P_{n}=  \lim\limits_{n\rightarrow \infty}\int\limits_{0}^{\tau}\, \sum\limits_{i=0}^{n}\frac{t^{i}}{i!}G_{i+1}\, dt = \int\limits_{0}^{\tau}\,\lim\limits_{n\rightarrow \infty} \sum\limits_{i=0}^{n}\frac{t^{i}}{i!}G_{i+1}\, dt = \int\limits_{0}^{\tau}\,G(t)\,dt = P
\end{equation}
where the limit was moved inside due to the dominated convergence theorem. Furthermore,
\begin{equation}
  \int\limits_{0}^{\tau}\frac{t^{i}}{i!}G_{i+1}\, dt = [G_{i},A]\frac{\tau^{i+1}}{(i+1)!},
\end{equation}
for every $i$. Thus
\begin{equation}
  P  =  \lim\limits_{n\rightarrow \infty} \sum\limits_{i=0}^{n} \int\limits_{0}^{\tau}\,\frac{t^{i}}{i!}G_{i+1}\, dt =  \sum\limits_{i=0}^{\infty}[G_{i},A]\frac{\tau^{i+1}}{(i+1)!}.
\end{equation}


\subsection*{(d)}
Task: Let $C_k = [C_{k-1},A]$, with $C_0 = B$. We want to show that $\|C_k\|\leq 2^k\|A\|^k\|B\|$.

The proof is done by induction. For $k = 0$ we have that $\|C_0\| = \|B\|\leq 2^0\|A\|^0\|B\|$. Now, assume that $\|C_k\|\leq 2^k\|A\|^k\|B\|$. We want to show that
$\|C_{k+1}\|\leq 2^{k+1}\|A\|^{k+1}\|B\|$:

\begin{equation}
\begin{aligned}
\|C_{k+1}\| = \|C_kA-AC_k\| = \|C_{k}A+(-AC_k)\|\leq\|C_kA\|+\|-AC_k\| = \|C_kA+|-1|\|AC_k\|\leq\|C_k\|\|A\|+\|A\|\|C_k\| =\\
= 2\|A\|\|C_k\| = 2^{k+1}\|A\|^{k+1}\|B\|,
\end{aligned}
\end{equation}
which is what we wanted to show.
\subsection*{(e)}
Suppose $\|A\|<\frac{1}{2}$ and $t\leq 1$. Let $G_N(t)$ be the truncation of $G(t)$, where
\begin{equation}
G(t) = \sum^{\infty}_{k = 0}\frac{t^k}{k!}C_k.
\end{equation}
Then,
\begin{equation}
\begin{aligned}
\|G_N(t)-G(t)\|&= \|\sum^{\infty}_{k = N+1}\frac{t^k}{k!}C_k\|\leq\sum^{\infty}_{k = N+1}\left(\frac{t^k}{k!}\right)\|C_k\|\leq\\
&\leq \sum^{\infty}_{k = N+1}\left(\frac{t^k}{k!}\right)2^k\|A\|^k\|B\|\leq \|B\|\sum^{\infty}_{k = N+1}\frac{t^k}{k!} = \|B\|\left(\sum^{\infty}_{k = 0}\frac{t^k}{k!}-\sum^{N}_{k = 0}\frac{t^k}{k!}\right) =  \|B\|\left(e^{t}-\sum^{N}_{k = 0}\frac{t^k}{k!}\right).
\end{aligned}
\end{equation}
where we have first used the result from (d). Passing the limit $N\rightarrow \infty$ we see that $\|G_N(t)-G(t)\| \rightarrow 0$. That is for all $\|A\|\leq 1$ and $t\leq 1$. This implies that
for some $N$ the difference $\|G_N(t)-G(t)\|$ is equal to the $N+1$:th term in the expansion, evaluated in some uknown point $T\in [0,1]$. In other words, the error bound is
\begin{equation}
  \|G_N(t)-G(t)\| = \|B\|\frac{t^{N+1}}{(N+1)!}e^{T}.
\end{equation}

\subsection*{(f)}
Using the results from (c), with
\begin{equation}
P = \sum^{\infty}_{i = 0}G_{i+1}\frac{\tau^{i+1}}{(i+1)!} = \sum^{\infty}_{i = 1}G_{i}\frac{\tau^{i}}{i!} = \sum^{\infty}_{i = 0}G_{i}\frac{\tau^{i}}{i!}-B,
\end{equation}
we denote by $P^N$ the computation of $P$ truncated at $N$ terms and obtain that
\begin{equation}
\|P-P^N\|= \|G_N(\tau)-G(\tau)\|.
\end{equation}
Using the estimate in (e), we thus have that
\begin{equation}
\|P_N-P\|\leq\int\limits_{0}^{\tau}\|B\|\frac{t^{N+1}}{(N+1)!}e^{T} =  \|B\|\frac{\tau^{N+2}}{(N+2)!}e^{T},\quad T\in [0,\tau].
\end{equation}
Thus we may a priori estimate the number of iterations that are required by estimating the error as $1/(N+2)!$.
now design an algorithm for $P$ (in pseudocode) as:

\begin{algorithm}[H]
 G = B;  - Sets initial element $G_0$.\\
 P = G; - Sets initial element, as we start at i = 1\\
 i = 1; - Number of iterations \\
 err = 1;\\
 t = 1;\\
 \For{i = 1:N}{
  G = GA-AG;\\
  t = t$\tau/i$;\\
  P = P+Gt;\\
 }
 \caption{Algorithm for computing the integral $P$.}
\end{algorithm}

\subsection*{(g)}
We compare the algorithm in (f) to the naice numerical integration approach in Julia. We use $\tau = 1$ and the Neumann matrix from the library of the package  MatrixDepot. See the attached code. We set an tolerance of $1e-14$. For the algorithm devised in (f) the CPU time in secons, including estimating $N$, is about $0.03$ seconds and the estimated error is $2.8e-15$. As a substitute for Matlabs integral we used \texttt{quadgk} from the package sharing its name. The corresponding time is $1.21$ seconds, which is about $33$ times slower. The estimated error, which \texttt{quadgk} gives as an output, is $1.0e-14$. The difference between the two results are about $1e-14$.
